{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOzzQRWel8AgUVpT9mbm5xS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geomyll33/Beautez/blob/master/DNN_optimizer%20lr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpQfgjl0SRxu"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGwCgE4tSdst"
      },
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None):\r\n",
        "    plt.plot(time[start:end], series[start:end], format)\r\n",
        "    plt.xlabel(\"Time\")\r\n",
        "    plt.ylabel(\"Value\")\r\n",
        "    plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7BOCEZsSff1"
      },
      "source": [
        "import csv\r\n",
        "time_step = []\r\n",
        "temps = []\r\n",
        "\r\n",
        "with open('/content/ευδαπ_dataset_527085.csv') as csvfile:\r\n",
        "  reader = csv.reader(csvfile, delimiter=',')\r\n",
        "  next(reader)\r\n",
        "  step=0\r\n",
        "  for row in reader:\r\n",
        "    temps.append(float(row[1]))\r\n",
        "    time_step.append(step)\r\n",
        "    step = step + 1\r\n",
        "\r\n",
        "series = np.array(temps)\r\n",
        "time = np.array(time_step)\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "plot_series(time, series)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ow5tLQQSjCe"
      },
      "source": [
        "split_time = 40\r\n",
        "time_train = time[:split_time]\r\n",
        "x_train = series[:split_time]\r\n",
        "time_valid = time[split_time:]\r\n",
        "x_valid = series[split_time:]\r\n",
        "\r\n",
        "window_size = 3\r\n",
        "batch_size = 2\r\n",
        "shuffle_buffer_size = 3\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "plot_series(time_train, x_train)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "plot_series(time_valid, x_valid)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ2_NSyjSlcw"
      },
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\r\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series)\r\n",
        "  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\r\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\r\n",
        "  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\r\n",
        "  dataset = dataset.batch(batch_size).prefetch(1)\r\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HceLOgXsS9DW"
      },
      "source": [
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\r\n",
        "\r\n",
        "\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "    tf.keras.layers.Dense(10, input_shape=[window_size], activation=\"relu\"), \r\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\"), \r\n",
        "    tf.keras.layers.Dense(1)\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9))\r\n",
        "model.fit(dataset,epochs=100,verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4rI1BvlS_h3"
      },
      "source": [
        "forecast = []\r\n",
        "for time in range(len(series) - window_size):\r\n",
        "  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\r\n",
        "\r\n",
        "forecast = forecast[split_time-window_size:]\r\n",
        "results = np.array(forecast)[:, 0, 0]\r\n",
        "\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "\r\n",
        "plot_series(time_valid, x_valid)\r\n",
        "plot_series(time_valid, results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAhtESVXTBj5"
      },
      "source": [
        "tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gyFmeuiTDYq"
      },
      "source": [
        "learning rate optimiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0trUbfqTFjb"
      },
      "source": [
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\r\n",
        "\r\n",
        "\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "    tf.keras.layers.Dense(10, input_shape=[window_size], activation=\"relu\"), \r\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\"), \r\n",
        "    tf.keras.layers.Dense(1)\r\n",
        "])\r\n",
        "\r\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\r\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 20))\r\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\r\n",
        "model.compile(loss=\"mse\", optimizer=optimizer)\r\n",
        "history = model.fit(dataset, epochs=100, callbacks=[lr_schedule], verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDkxbP44THZV"
      },
      "source": [
        "lrs = 1e-10 * (10 ** (np.arange(100) /20))\r\n",
        "plt.semilogx(lrs, history.history[\"loss\"])\r\n",
        "plt.axis([1e-10, 1e-1, 0, 500])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fywLKvATJM-"
      },
      "source": [
        "window_size = 3\r\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\r\n",
        "\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\", input_shape=[window_size]),\r\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\r\n",
        "  tf.keras.layers.Dense(1)\r\n",
        "])\r\n",
        "\r\n",
        "optimizer = tf.keras.optimizers.SGD(lr=4e-8, momentum=0.7)\r\n",
        "model.compile(loss=\"mse\", optimizer=optimizer)\r\n",
        "history = model.fit(dataset, epochs=500, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvtqFo_1TK_Y"
      },
      "source": [
        "loss = history.history['loss']\r\n",
        "epochs = range(len(loss))\r\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWXaUlL8TM6I"
      },
      "source": [
        "# Plot all but the first 10\r\n",
        "loss = history.history['loss']\r\n",
        "epochs = range(10, len(loss))\r\n",
        "plot_loss = loss[10:]\r\n",
        "print(plot_loss)\r\n",
        "plt.plot(epochs, plot_loss, 'b', label='Training Loss')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ciuw-oRHTPW5"
      },
      "source": [
        "forecast = []\r\n",
        "for time in range(len(series) - window_size):\r\n",
        "  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\r\n",
        "\r\n",
        "forecast = forecast[split_time-window_size:]\r\n",
        "results = np.array(forecast)[:, 0, 0]\r\n",
        "\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "\r\n",
        "plot_series(time_valid, x_valid)\r\n",
        "plot_series(time_valid, results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYXMeuHxTRTs"
      },
      "source": [
        "tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}